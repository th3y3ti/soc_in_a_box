import os
import logging
from typing import List, Dict, Optional, Any
from pydantic import BaseModel, Field
from dotenv import load_dotenv
from jira import JIRA
import requests
import base64
import google.generativeai as genai

# --- Configuration ---
load_dotenv()
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
)
logger = logging.getLogger(__name__)

# Configure Gemini API
try:
    genai.configure(api_key=os.getenv('GOOGLE_API_KEY'))
    gemini_model_name = 'gemini-1.5-flash' # Or choose another appropriate model
    # Check if the API key is loaded
    if not os.getenv('GOOGLE_API_KEY'):
        logger.error("GOOGLE_API_KEY environment variable not found.")
        # Consider exiting or raising an error depending on your flow
except Exception as e:
    logger.error(f"Failed to configure Gemini API: {e}")
    # Handle configuration error

# --- Jira Configuration (Ensure these are set in your .env file) ---
JIRA_BASE_URL = os.getenv('JIRA_BASE_URL')
JIRA_API_KEY = os.getenv('JIRA_API_KEY')
JIRA_EMAIL = os.getenv('JIRA_EMAIL')

# --- Pydantic Data Models ---

class CountermeasureInput(BaseModel):
    """Initial details of the new countermeasure."""
    name: str = Field(description="Proposed name or title for the countermeasure")
    description: str = Field(description="Detailed description of the vulnerability or threat it addresses")
    type: str = Field(default="Generic", description="Type or category of the countermeasure (e.g., Network, Endpoint, Cloud)")
    source_reference: Optional[str] = Field(default=None, description="Link or reference to the source requiring the countermeasure")

class VectorSearchResult(BaseModel):
    """Results from searching the vector store for existing countermeasures."""
    found_similar: bool = Field(description="Whether potentially similar countermeasures were found")
    similar_countermeasures: List[Dict[str, Any]] = Field(default_factory=list, description="List of similar countermeasures found (e.g., {'id': 'CM-123', 'summary': '...', 'similarity_score': 0.85})")
    search_summary: str = Field(description="A brief summary of the search findings")

class ConfluenceKnowledge(BaseModel):
    """Knowledge gathered from Confluence."""
    found_pages: bool = Field(description="Whether relevant Confluence pages were found")
    relevant_pages_summary: Optional[str] = Field(default=None, description="Summary of key information from relevant pages")
    page_links: List[str] = Field(default_factory=list, description="Links to relevant Confluence pages")

class JiraTicketContentInput(BaseModel):
    """Data used by Gemini to generate the Jira ticket description."""
    initial_input: CountermeasureInput
    vector_search: VectorSearchResult
    confluence_knowledge: ConfluenceKnowledge

class GeneratedJiraContent(BaseModel):
    """Content generated by the LLM for the Jira ticket."""
    suggested_summary: str = Field(description="A concise summary/title for the Jira ticket")
    detailed_description: str = Field(description="The detailed description for the Jira ticket body, formatted with markdown")

class JiraTicketDetails(BaseModel):
    """Final details required to create the Jira ticket."""
    project_key: str = Field(description="Jira Project Key (e.g., 'SOC', 'SEC')")
    summary: str
    description: str
    issuetype_name: str = Field(default="Task", description="Name of the Jira issue type")
    priority_name: str = Field(default="Medium", description="Name of the Jira priority")
    labels: List[str] = Field(default_factory=list, description="List of labels for the Jira ticket")

class OrchestrationResult(BaseModel):
    """Output of the entire orchestration process."""
    success: bool
    message: str
    jira_issue_key: Optional[str] = None
    generated_content: Optional[GeneratedJiraContent] = None
    vector_search_result: Optional[VectorSearchResult] = None
    confluence_knowledge_result: Optional[ConfluenceKnowledge] = None
    confluence_page_id: Optional[str] = None
    confluence_page_url: Optional[str] = None


# --- Prompts ---

JIRA_DESCRIPTION_GENERATION_PROMPT = """
You are an assistant tasked with creating a detailed Jira ticket for a new security countermeasure.
Use the information provided below to generate a concise 'suggested_summary' and a comprehensive 'detailed_description' for the ticket.

**1. Initial Countermeasure Request:**
   - Name/Title: {countermeasure_name}
   - Description: {countermeasure_description}
   - Type: {countermeasure_type}
   - Source Reference: {source_reference}

**2. Existing Countermeasure Check (Vector Search Results):**
   - Similar Found: {found_similar}
   - Search Summary: {search_summary}
   - Details of Similar (if any): {similar_details}

**3. Related Knowledge (Confluence Search Results):**
   - Pages Found: {found_pages}
   - Knowledge Summary: {knowledge_summary}
   - Relevant Links: {page_links}

**Instructions for Generating Content:**

* **Suggested Summary:** Create a brief, informative title for the Jira ticket (e.g., "New Countermeasure: Block Malicious Domain [Domain Name]", "Develop Detection Logic for CVE-XXXX-YYYY"). Incorporate the core idea of the countermeasure.
* **Detailed Description:** Create a well-structured description using Markdown. Include the following sections:
    * **Overview:** Briefly describe the purpose of this new countermeasure based on the initial request.
    * **Threat/Vulnerability Addressed:** Detail the specific problem this countermeasure aims to solve (use `countermeasure_description`).
    * **Existing Coverage Analysis:** Summarize the findings from the vector search (`search_summary`). If similar countermeasures exist, mention them briefly and explain why this new one is still needed (or if it might be a duplicate). Link to similar items if provided (`similar_details`).
    * **Related Knowledge:** Incorporate key information from the Confluence search (`knowledge_summary`). Include links to the relevant pages (`page_links`) for further reading.
    * **Proposed Action:** Clearly state the action required (e.g., "Implement firewall rule", "Create SIEM detection rule", "Update endpoint policy").
    * **Details:** Include `countermeasure_type` and `source_reference`.
    * **Priority Justification (Optional but Recommended):** Briefly explain why the proposed priority is appropriate.

Ensure the output is clear, actionable, and provides context for the team implementing the countermeasure.
"""

# --- Agent Components ---

class VectorSearchAgent:
    """Agent responsible for searching the vector store."""
    def __init__(self, connection_string: Optional[str] = None):
        # TODO: Initialize connection to your PostgreSQL vector store
        # Example: self.conn = psycopg2.connect(connection_string)
        # Example: self.vector_column = 'embedding'
        # Example: self.text_column = 'content'
        # Example: self.metadata_columns = ['id', 'summary']
        logger.info("VectorSearchAgent initialized (Placeholder)")
        # Replace with actual vector store library (e.g., pgvector, pg_embedding)

    def search_similar(self, query_text: str, top_k: int = 3, threshold: float = 0.75) -> VectorSearchResult:
        """Searches for similar countermeasures in the vector store."""
        logger.info(f"Searching vector store for: '{query_text[:50]}...'")
        # --- Placeholder Implementation ---
        # TODO: Replace with actual vector search logic
        # 1. Generate embedding for query_text (using the same model as stored embeddings)
        # 2. Query PostgreSQL: SELECT id, summary, content, embedding <-> query_embedding AS distance
        #    FROM countermeasures WHERE embedding <-> query_embedding < (1 - threshold) ORDER BY distance LIMIT top_k;
        # 3. Process results
        # Example Dummy Result:
        similar_found = False # Change based on actual results
        similar_items = []
        if similar_found:
             similar_items = [
                 {'id': 'CM-456', 'summary': 'Existing related countermeasure A', 'similarity_score': 0.88},
                 {'id': 'CM-789', 'summary': 'Another similar countermeasure B', 'similarity_score': 0.82}
             ]
             search_summary = f"Found {len(similar_items)} potentially similar countermeasures above similarity threshold {threshold}."
        else:
            search_summary = f"No similar countermeasures found above similarity threshold {threshold}."
        # --- End Placeholder ---

        logger.info(f"Vector search summary: {search_summary}")
        return VectorSearchResult(
            found_similar=similar_found,
            similar_countermeasures=similar_items,
            search_summary=search_summary
        )

class ConfluenceAgent:
    """Agent responsible for gathering knowledge from Confluence."""
    def __init__(self, confluence_url: Optional[str] = None, username: Optional[str] = None, api_token: Optional[str] = None):
        # TODO: Initialize Confluence API client
        # Example using atlassian-python-api:
        # from atlassian import Confluence
        # self.confluence = Confluence(url=confluence_url, username=username, password=api_token)
        self.confluence_url = confluence_url
        self.username = username
        self.api_token = api_token
        logger.info("ConfluenceAgent initialized (Placeholder)")

    def gather_knowledge(self, search_query: str, space_key: str = "KB", max_pages: int = 3) -> ConfluenceKnowledge:
        """Searches Confluence for relevant pages."""
        logger.info(f"Searching Confluence (space: {space_key}) for: '{search_query}'")
        # --- Placeholder Implementation ---
        # TODO: Replace with actual Confluence search logic
        # 1. Use Confluence API to search (e.g., self.confluence.cql(f'space="{space_key}" and text ~ "{search_query}"', limit=max_pages))
        # 2. Extract relevant summaries and links from search results.
        # Example Dummy Result:
        found = False # Change based on actual results
        summary = None
        links = []
        if found:
            summary = "Found pages discussing related threat intelligence and standard operating procedures."
            links = ["https://your.confluence.com/display/KB/Page1", "https://your.confluence.com/display/KB/Page2"]
        else:
            summary = "No directly relevant pages found in the specified Confluence space."
        # --- End Placeholder ---

        logger.info(f"Confluence search summary: {summary}")
        return ConfluenceKnowledge(
            found_pages=found,
            relevant_pages_summary=summary,
            page_links=links
        )
        
    def get_recent_pages(self, space_key: str = "SO", folder_path: str = "Daily Intel Reports", hours: int = 24) -> List[Dict[str, Any]]:
        """Fetches Confluence pages created in the last specified hours within a specific folder."""
        logger.info(f"Fetching Confluence pages from space '{space_key}', folder '{folder_path}', created in the last {hours} hours")
        
        try:
            # Get Confluence credentials from environment variables if not provided
            email = self.username or os.getenv('CONFLUENCE_USERNAME')
            api_token = self.api_token or os.getenv('CONFLUENCE_API_TOKEN')
            
            if not email or not api_token:
                logger.error("Confluence credentials not found in environment variables")
                return []
                
            # Calculate the time threshold (24 hours ago)
            from datetime import datetime, timedelta
            time_threshold = datetime.now() - timedelta(hours=hours)
            time_threshold_str = time_threshold.strftime("%Y-%m-%dT%H:%M:%S.000Z")
            
            # Prepare headers for the API request
            headers = {
                'Authorization': f'Basic {base64.b64encode(f"{email}:{api_token}".encode()).decode()}',
                'Content-Type': 'application/json',
                'Accept': 'application/json'
            }
            
            # Construct the CQL query to find pages created in the last 24 hours in the specified space
            # Using the Confluence REST API with CQL
            base_url = self.confluence_url or os.getenv('CONFLUENCE_URL', 'https://roberthigham.atlassian.net/wiki')
            api_url = f"{base_url}/rest/api/content"
            
            # First, find the folder ID for the specified path
            # We'll use the CQL to find the parent page by title
            parent_cql = f'space="{space_key}" and title="{folder_path}" and type=page'
            parent_params = {
                'cql': parent_cql,
                'limit': 1
            }
            
            parent_response = requests.get(api_url, headers=headers, params=parent_params)
            parent_response.raise_for_status()
            parent_data = parent_response.json()
            
            if not parent_data.get('results'):
                logger.error(f"Could not find folder '{folder_path}' in space '{space_key}'")
                return []
            
            parent_id = parent_data['results'][0]['id']
            logger.info(f"Found folder '{folder_path}' with ID: {parent_id}")
            
            # Find pages under the parent created in the last 24 hours
            # Add a title filter to only get Metasploit module analysis pages
            cql_query = f'space="{space_key}" and ancestor={parent_id} and created >= "{time_threshold_str}" and type=page and title ~ "Metasploit Module Analysis:"'
            
            params = {
                'cql': cql_query,
                'expand': 'version,body.storage',
                'limit': 50  # Limit to 50 pages to avoid overwhelming the API
            }
            
            # Make the API request
            response = requests.get(api_url, headers=headers, params=params)
            response.raise_for_status()
            
            # Parse the response
            data = response.json()
            pages = data.get('results', [])
            
            logger.info(f"Found {len(pages)} Metasploit module analysis pages in folder '{folder_path}' created in the last {hours} hours")
            
            # Extract relevant information from each page
            result = []
            for page in pages:
                page_info = {
                    'id': page.get('id'),
                    'title': page.get('title'),
                    'url': f"{base_url}/pages/viewpage.action?pageId={page.get('id')}",
                    'created': page.get('version', {}).get('created'),
                    'content': page.get('body', {}).get('storage', {}).get('value', '')
                }
                result.append(page_info)
                
            return result
            
        except Exception as e:
            logger.error(f"Error fetching recent Confluence pages: {e}")
            if hasattr(e, 'response') and e.response is not None:
                logger.error(f"Response status: {e.response.status_code}")
                logger.error(f"Response body: {e.response.text}")
            return []

class JiraContentGenerator:
    """Agent responsible for generating Jira ticket content using Gemini."""
    def __init__(self, model_name: str = gemini_model_name):
        """Initialize the Jira Content Generator"""
        try:
            self.model = genai.GenerativeModel(model_name)
            logger.info(f"JiraContentGenerator initialized with model: {model_name}")
        except Exception as e:
            logger.error(f"Failed to initialize Gemini model {model_name}: {e}")
            self.model = None # Ensure model is None if initialization fails

    def generate_content(self, content_input: JiraTicketContentInput) -> Optional[GeneratedJiraContent]:
        """Generate Jira summary and description using Gemini."""
        if not self.model:
            logger.error("Gemini model not initialized. Cannot generate content.")
            return None

        logger.info("Generating Jira content using Gemini...")

        prompt = JIRA_DESCRIPTION_GENERATION_PROMPT.format(
            countermeasure_name=content_input.initial_input.name,
            countermeasure_description=content_input.initial_input.description,
            countermeasure_type=content_input.initial_input.type,
            source_reference=content_input.initial_input.source_reference or "N/A",
            found_similar=content_input.vector_search.found_similar,
            search_summary=content_input.vector_search.search_summary,
            similar_details=str(content_input.vector_search.similar_countermeasures) if content_input.vector_search.found_similar else "N/A",
            found_pages=content_input.confluence_knowledge.found_pages,
            knowledge_summary=content_input.confluence_knowledge.relevant_pages_summary or "N/A",
            page_links='\n'.join(content_input.confluence_knowledge.page_links) if content_input.confluence_knowledge.page_links else "N/A",
        )

        try:
            # Using generate_content for potential streaming or richer responses later
            response = self.model.generate_content(prompt)

            # Assuming the response text contains the summary and description clearly separated or parsable.
            # This might need refinement based on actual Gemini output structure.
            # A more robust approach would use Gemini's function calling or structured output features if available.
            # For now, let's assume a simple split or parse logic.
            # --- Simple Parsing Logic (Example - NEEDS ADJUSTMENT) ---
            response_text = response.text
            # logger.debug(f"Raw Gemini Response:\n{response_text}") # Log raw response for debugging

            # Try to parse based on expected headers (adjust based on actual LLM output)
            summary = "Default Summary - Parsing Failed"
            description = response_text # Default to full text if parsing fails

            summary_marker = "**Suggested Summary:**"
            description_marker = "**Detailed Description:**"

            summary_start = response_text.find(summary_marker)
            description_start = response_text.find(description_marker)

            if summary_start != -1 and description_start != -1:
                summary_text_start = summary_start + len(summary_marker)
                summary = response_text[summary_text_start:description_start].strip()
                description = response_text[description_start + len(description_marker):].strip()
            elif description_start != -1: # Only found description marker
                 logger.warning("Could not parse suggested_summary from LLM response.")
                 description = response_text[description_start + len(description_marker):].strip()
            else: # Could not find markers
                logger.warning("Could not parse summary/description markers from LLM response. Using defaults.")

            # --- End Simple Parsing Logic ---

            logger.info("Successfully generated Jira content from Gemini.")
            return GeneratedJiraContent(
                suggested_summary=summary,
                detailed_description=description
            )
        except Exception as e:
            logger.error(f"Error generating Jira content description via Gemini: {str(e)}")
            return None

class JiraCreationTool:
    """Tool for creating Jira tickets."""
    def __init__(self, jira_client: JIRA):
        self.jira = jira_client
        logger.info(f"Successfully connected to Jira at {self.jira.server_url}")

    def create_ticket(self, details: JiraTicketDetails) -> Optional[str]:
        """Creates a Jira ticket with the given details."""
        try:
            logger.info(f"Attempting to create Jira ticket in project: {details.project_key}")
            
            # Create the issue without priority field
            issue_dict = {
                'project': {'key': details.project_key},
                'summary': details.summary,
                'description': details.description,
                'issuetype': {'name': details.issuetype_name},
                'labels': details.labels
            }

            # Create the issue
            new_issue = self.jira.create_issue(fields=issue_dict)
            logger.info(f"Successfully created Jira ticket: {new_issue.key}")
            return new_issue.key

        except Exception as e:
            logger.error(f"Error creating Jira ticket: {e}")
            if hasattr(e, 'response'):
                logger.error(f"Jira API Error Details: {e.response.json()}")
            return None

# --- Orchestrator ---

class CountermeasureJiraOrchestrator:
    def __init__(self):
        # Initialize agents/tools - dependencies injected or fetched from config
        self.vector_searcher = VectorSearchAgent() # Add connection details if needed
        self.confluence_reader = ConfluenceAgent(
            confluence_url=os.getenv("CONFLUENCE_URL"), # Add CONFLUENCE_URL to .env
            username=os.getenv("CONFLUENCE_USERNAME"), # Add CONFLUENCE_USERNAME to .env
            api_token=os.getenv("CONFLUENCE_API_TOKEN") # Add CONFLUENCE_API_TOKEN to .env
        )
        self.content_generator = JiraContentGenerator()
        self.jira_creator = JiraCreationTool(
            jira_client=JIRA(
                server=JIRA_BASE_URL,
                basic_auth=(JIRA_EMAIL, JIRA_API_KEY)
            )
        )
        logger.info("CountermeasureJiraOrchestrator initialized.")

    def process_new_countermeasure(self, initial_input: CountermeasureInput, project_key: str = "SOC") -> OrchestrationResult:
        """Orchestrates the process of creating a Jira ticket for a new countermeasure."""
        logger.info(f"Starting process for countermeasure: {initial_input.name}")

        # 1. Vector Search
        try:
            # Use a combination of name and description for a richer search query
            search_query = f"{initial_input.name} - {initial_input.description}"
            vector_result = self.vector_searcher.search_similar(search_query)
        except Exception as e:
            logger.error(f"Vector search failed: {e}")
            return OrchestrationResult(success=False, message=f"Vector search failed: {e}")

        # 2. Confluence Knowledge Gathering
        try:
            # Use the countermeasure name/description as search query for Confluence
            confluence_result = self.confluence_reader.gather_knowledge(initial_input.description)
        except Exception as e:
            logger.error(f"Confluence search failed: {e}")
            # Continue process, but log the error - knowledge might be optional
            confluence_result = ConfluenceKnowledge(found_pages=False, relevant_pages_summary=f"Confluence search failed: {e}", page_links=[])


        # 3. Generate Jira Content using LLM
        content_input = JiraTicketContentInput(
            initial_input=initial_input,
            vector_search=vector_result,
            confluence_knowledge=confluence_result
        )
        generated_content = self.content_generator.generate_content(content_input)
        if not generated_content:
            logger.error("Failed to generate Jira content.")
            return OrchestrationResult(
                success=False,
                message="Failed to generate Jira content via LLM.",
                vector_search_result=vector_result,
                confluence_knowledge_result=confluence_result
            )

        # (Optional) Add logic here: If vector search found very high similarity, maybe ask for confirmation or stop?
        if vector_result.found_similar:
             logger.warning(f"Potential duplicates found: {vector_result.similar_countermeasures}. Proceeding with creation, but review recommended.")
             # You could add a flag or specific note in the description here.

        # 4. Prepare Jira Ticket Details
        ticket_details = JiraTicketDetails(
            project_key=project_key, # Make project key configurable
            summary=generated_content.suggested_summary,
            description=generated_content.detailed_description,
            issuetype_name="Task", # Or make configurable
            priority_name="Medium", # Or make configurable, or derive from analysis
            labels=["countermeasure", initial_input.type.lower(), "autogenerated"] # Add relevant labels
        )

        # 5. Create Jira Ticket
        issue_key = self.jira_creator.create_ticket(ticket_details)

        if issue_key:
            logger.info(f"Successfully completed process. Jira issue created: {issue_key}")
            return OrchestrationResult(
                success=True,
                message=f"Jira issue created successfully: {issue_key}",
                jira_issue_key=issue_key,
                generated_content=generated_content,
                vector_search_result=vector_result,
                confluence_knowledge_result=confluence_result
            )
        else:
            logger.error("Failed to create Jira ticket.")
            return OrchestrationResult(
                success=False,
                message="Failed to create Jira ticket.",
                generated_content=generated_content, # Include generated content for debugging
                vector_search_result=vector_result,
                confluence_knowledge_result=confluence_result
            )
            
    def process_recent_confluence_pages(self, space_key: str = "SO", folder_path: str = "Daily Intel Reports", hours: int = 24, project_key: str = "SOC") -> List[OrchestrationResult]:
        """Processes recent Confluence pages and creates Jira tickets based on them."""
        logger.info(f"Processing Confluence pages from space '{space_key}', folder '{folder_path}', created in the last {hours} hours")
        
        # Get recent pages from Confluence
        recent_pages = self.confluence_reader.get_recent_pages(space_key=space_key, folder_path=folder_path, hours=hours)
        
        if not recent_pages:
            logger.info(f"No Confluence pages found in space '{space_key}', folder '{folder_path}', created in the last {hours} hours")
            return []
            
        logger.info(f"Found {len(recent_pages)} Confluence pages to process")
        
        results = []
        for page in recent_pages:
            try:
                # Extract title and content from the page
                title = page.get('title', '')
                content = page.get('content', '')
                page_url = page.get('url', '')
                
                # Skip pages that don't have a title or content
                if not title or not content:
                    logger.warning(f"Skipping page with ID {page.get('id')} due to missing title or content")
                    continue
                
                # Create a countermeasure input based on the page content
                # We'll use the page title as the name and extract a description from the content
                # This is a simple approach - you might want to enhance this with better content parsing
                
                # Extract a description from the content (first 500 characters or so)
                description = content[:500] + "..." if len(content) > 500 else content
                
                # Create the countermeasure input
                countermeasure_input = CountermeasureInput(
                    name=title,
                    description=description,
                    type="Intelligence",  # Default type for Confluence-sourced countermeasures
                    source_reference=page_url
                )
                
                # Process the countermeasure and create a Jira ticket
                result = self.process_new_countermeasure(countermeasure_input, project_key=project_key)
                
                # Add the Confluence page ID to the result for reference
                result.confluence_page_id = page.get('id')
                result.confluence_page_url = page_url
                
                results.append(result)
                
            except Exception as e:
                logger.error(f"Error processing Confluence page {page.get('id')}: {e}")
                # Continue with the next page
                continue
                
        logger.info(f"Processed {len(results)} Confluence pages and created {sum(1 for r in results if r.success)} Jira tickets")
        return results


# --- Example Usage ---

if __name__ == "__main__":
    # Ensure environment variables are loaded (especially API keys and URLs)
    if not all([os.getenv('GOOGLE_API_KEY'), JIRA_BASE_URL, JIRA_API_KEY, JIRA_EMAIL]):
         logger.error("Missing critical environment variables (Gemini Key, Jira URL/Email/Token). Please check your .env file or environment.")
         # exit(1) # Optional: exit if config is missing

    orchestrator = CountermeasureJiraOrchestrator()

    # Example 1: Create a Jira ticket for a specific countermeasure
    new_cm = CountermeasureInput(
        name="Block Outbound Connection to Known C2 Domain XYZ",
        description="Observed endpoint attempting to connect to known command-and-control domain 'malicious-domain.example.com' (IP: 192.0.2.100) via TCP port 8080. Need to block this at the firewall.",
        type="Network",
        source_reference="Alert ID: SIEM-ALERT-54321"
    )

    # Define the target Jira project
    target_project = "SOC" # Or fetch from config/argument

    # Run the process
    result = orchestrator.process_new_countermeasure(new_cm, project_key=target_project)

    print("\n--- Orchestration Result ---")
    print(f"Success: {result.success}")
    print(f"Message: {result.message}")
    if result.jira_issue_key:
        print(f"Jira Issue Key: {result.jira_issue_key}")
        jira_link = f"{JIRA_BASE_URL}/browse/{result.jira_issue_key}" if JIRA_BASE_URL else "Link unavailable"
        print(f"Jira Link: {jira_link}")

    # Example 2: Process recent Confluence pages and create Jira tickets
    print("\n--- Processing Recent Confluence Pages ---")
    confluence_space = "SO"  # Space where intel_agent.py creates pages
    confluence_folder = "Daily Intel Reports"  # Folder where intel_agent.py creates pages
    hours = 24  # Look for pages created in the last 24 hours
    
    results = orchestrator.process_recent_confluence_pages(
        space_key=confluence_space,
        folder_path=confluence_folder,
        hours=hours,
        project_key=target_project
    )
    
    print(f"Processed {len(results)} Confluence pages")
    for i, result in enumerate(results, 1):
        print(f"\nResult {i}:")
        print(f"Success: {result.success}")
        print(f"Message: {result.message}")
        if result.jira_issue_key:
            print(f"Jira Issue Key: {result.jira_issue_key}")
            jira_link = f"{JIRA_BASE_URL}/browse/{result.jira_issue_key}" if JIRA_BASE_URL else "Link unavailable"
            print(f"Jira Link: {jira_link}")
        if result.confluence_page_url:
            print(f"Confluence Page: {result.confluence_page_url}")